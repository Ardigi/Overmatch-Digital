# Docker Compose Production Configuration
# This file contains production-specific overrides for Docker Swarm deployment
# Usage: docker stack deploy -c docker-compose.yml -c docker-compose.secrets.yml -c docker-compose.production.yml soc-platform

version: '3.8'

# External secrets for production (managed outside of Compose)
secrets:
  postgres_password:
    external: true
    name: soc_postgres_password
  postgres_user:
    external: true
    name: soc_postgres_user
  redis_password:
    external: true
    name: soc_redis_password
  mongo_root_password:
    external: true
    name: soc_mongo_root_password
  mongo_root_username:
    external: true
    name: soc_mongo_root_username
  jwt_secret:
    external: true
    name: soc_jwt_secret
  aws_access_key_id:
    external: true
    name: soc_aws_access_key_id
  aws_secret_access_key:
    external: true
    name: soc_aws_secret_access_key
  smtp_user:
    external: true
    name: soc_smtp_user
  smtp_pass:
    external: true
    name: soc_smtp_pass
  openai_api_key:
    external: true
    name: soc_openai_api_key
  grafana_admin_password:
    external: true
    name: soc_grafana_admin_password

services:
  # Kong API Gateway - Production Configuration
  kong:
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    environment:
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_LOG_LEVEL: warn
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # PostgreSQL - Production Configuration
  postgres:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.postgres == true
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    environment:
      POSTGRES_SHARED_PRELOAD_LIBRARIES: pg_stat_statements
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - postgres-backups:/backups
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Redis - Production Configuration
  redis:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.redis == true
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    command: >
      redis-server 
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # MongoDB - Production Configuration
  mongodb:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.mongodb == true
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    command: >
      mongod
      --auth
      --bind_ip_all
      --replSet rs0
      --oplogSize 1024
      --wiredTigerCacheSizeGB 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Elasticsearch - Production Configuration
  elasticsearch:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.elasticsearch == true
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    environment:
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - cluster.name=soc-cluster
      - node.name=soc-node-1
      - discovery.type=single-node
      - xpack.security.enabled=true
      - xpack.security.enrollment.enabled=true
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Kafka - Production Configuration
  kafka:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.kafka == true
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    environment:
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_CLEANUP_POLICY: delete
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Vault - Production Configuration
  vault:
    image: hashicorp/vault:1.15
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    environment:
      VAULT_LOCAL_CONFIG: |
        {
          "backend": {
            "consul": {
              "address": "consul:8500",
              "path": "vault/",
              "scheme": "http"
            }
          },
          "listener": {
            "tcp": {
              "address": "0.0.0.0:8200",
              "tls_cert_file": "/vault/tls/vault.crt",
              "tls_key_file": "/vault/tls/vault.key"
            }
          },
          "cluster_addr": "https://{{.Node.Hostname}}:8201",
          "api_addr": "https://vault.{{.Task.Slot}}.{{.Service.Name}}.{{.Task.ID}}.{{.Network.Name}}:8200",
          "ui": true,
          "default_lease_ttl": "168h",
          "max_lease_ttl": "720h"
        }
    volumes:
      - vault-tls:/vault/tls:ro
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Service configurations with production settings
  auth-service:
    deploy:
      replicas: 2
      placement:
        max_replicas_per_node: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    environment:
      NODE_ENV: production
      LOG_LEVEL: warn
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  client-service:
    deploy:
      replicas: 2
      placement:
        max_replicas_per_node: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    environment:
      NODE_ENV: production
      LOG_LEVEL: warn
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Repeat similar configuration for other services...
  audit-service:
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    environment:
      NODE_ENV: production
      LOG_LEVEL: warn
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Monitoring services
  prometheus:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.monitoring == true
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  grafana:
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.monitoring == true
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_USERS_ALLOW_SIGN_UP: false
      GF_SECURITY_DISABLE_GRAVATAR: true
      GF_ANALYTICS_REPORTING_ENABLED: false
      GF_ANALYTICS_CHECK_FOR_UPDATES: false
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# Production volumes with specific drivers and options
volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/postgres
  postgres-backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/backups/postgres
  mongo-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/mongodb
  elastic-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/elasticsearch
  redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/redis
  vault-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/vault
  vault-tls:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/tls/vault
  prometheus-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/prometheus
  grafana-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/soc-platform/data/grafana

# Production networks with specific configuration
networks:
  soc-network:
    driver: overlay
    driver_opts:
      encrypted: "true"
    attachable: false
    external: false
    labels:
      - "com.soc-platform.network=production"